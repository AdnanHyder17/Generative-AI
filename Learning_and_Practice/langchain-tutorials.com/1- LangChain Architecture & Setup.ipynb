{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03587cd8",
   "metadata": {},
   "source": [
    "## What is LangChain?\n",
    "\n",
    "LangChain is a powerful framework designed to simplify the development of applications powered by large language models (LLMs).  \n",
    "It provides a rich set of tools and abstractions that help developers build complex AI-powered applications efficiently and modularly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0419fe7",
   "metadata": {},
   "source": [
    "## üöÄ Without LangChain\n",
    "\n",
    "‚úó Write boilerplate code for each LLM integration  \n",
    "‚úó Manually handle prompt templates and formatting  \n",
    "‚úó Build your own memory management system  \n",
    "‚úó Create custom chains and workflows from scratch  \n",
    "\n",
    "\n",
    "## ‚ú® With LangChain\n",
    "\n",
    "‚úì Unified interface for all LLM providers  \n",
    "‚úì Built-in prompt templates and management  \n",
    "‚úì Ready-to-use memory and conversation history  \n",
    "‚úì Pre-built chains for common patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d83190",
   "metadata": {},
   "source": [
    "## üèóÔ∏è LangChain Architecture ‚Äì Core Components\n",
    "\n",
    "**1. Models ü§ñ**  \n",
    "The foundation ‚Äî interfaces to various LLMs (OpenAI, Anthropic, Ollama).  \n",
    "**Examples:** `ChatOpenAI`, `ChatAnthropic`, `Ollama`\n",
    "\n",
    "**2. Prompts üìù**  \n",
    "Templates and formatters for designing effective prompts.  \n",
    "**Examples:** `PromptTemplate`, `ChatPromptTemplate`, `FewShotPromptTemplate`\n",
    "\n",
    "**3. Memory üß†**  \n",
    "Systems for maintaining conversation context and history.  \n",
    "**Examples:** `ConversationBufferMemory`, `ConversationSummaryMemory`\n",
    "\n",
    "**4. Chains ‚õìÔ∏è**  \n",
    "Combine models, prompts, and memory into reusable workflows.  \n",
    "**Examples:** `LLMChain`, `ConversationChain`, `RetrievalQA`\n",
    "\n",
    "**5. Agents ü§ñ**  \n",
    "Autonomous decision-makers capable of using tools, chains, and logic.  \n",
    "**Examples:** `AgentExecutor`, `Tools`, `ReActAgent`\n",
    "\n",
    "---\n",
    "\n",
    "üí° **Key Insight:**  \n",
    "Each component builds on the previous one: start with **models**, add **prompts**, include **memory** if needed, structure them with **chains**, and finally create **agents** for complex tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8139ae",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è How to Install LangChain in Python  \n",
    "\n",
    "**1. Install LangChain and Required Dependencies**  \n",
    "```bash\n",
    "pip install langchain langchain-google-genai langchain-community python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9387086e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's a simple explanation of quantum computing:\n",
      "\n",
      "**Quantum computing uses the weird rules of quantum mechanics to solve problems too complex for regular computers.**\n",
      "\n",
      "*   **Regular computers:** Use bits that are either 0 or 1.\n",
      "*   **Quantum computers:** Use *qubits*. Qubits can be 0, 1, or *both at the same time* (called superposition). They also use *entanglement*, where qubits become linked and affect each other.\n",
      "\n",
      "**Why is this useful?**\n",
      "\n",
      "*   **More possibilities:** Qubits allow quantum computers to explore many possibilities simultaneously, making them potentially much faster for certain tasks.\n",
      "*   **Complex problems:** Quantum computers are promising for things like drug discovery, materials science, and breaking encryption.\n",
      "\n",
      "**In short:** Quantum computers are not replacements for your laptop. They are specialized tools for tackling incredibly difficult problems by exploiting the unique properties of quantum mechanics.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. First, get your Google AI API key:\n",
    "\n",
    "‚Ä¢ Go to Google AI Studio\n",
    "‚Ä¢ Click \"Create API Key\" (free to use)\n",
    "‚Ä¢ Copy your API key\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "2. Now create your LangChain application:\n",
    "\n",
    "What's happening here?\n",
    "We initialize a ChatGoogleGenerativeAI model (use the latest available model)\n",
    "Create a prompt template with system and human messages\n",
    "Combine them using the pipe operator (|) - the new recommended syntax\n",
    "Execute the chain with our input topic\n",
    "\"\"\"\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the model\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",  # Use latest model: gemini-2.0-flash, gemini-1.5-pro, etc.\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Create a prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that explains concepts clearly.\"),\n",
    "    (\"human\", \"Explain {topic} in simple terms using concise output.\")\n",
    "])\n",
    "\n",
    "# Create a chain using the new syntax (LLMChain is deprecated)\n",
    "chain = prompt | llm\n",
    "\n",
    "# Run the chain\n",
    "result = chain.invoke({\"topic\": \"quantum computing\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f303b1ee",
   "metadata": {},
   "source": [
    "## üß† Adding Memory to Your Application\n",
    "\n",
    "### **Why Memory Matters**\n",
    "Without memory, each interaction with the AI is isolated ‚Äî it cannot remember previous messages.  \n",
    "This makes it impossible to have natural conversations or build context-aware applications.\n",
    "\n",
    "---\n",
    "\n",
    "### **‚ùå Without Memory**\n",
    "**User:** \"My name is Alice\"  \n",
    "**AI:** \"Nice to meet you!\"  \n",
    "**User:** \"What's my name?\"  \n",
    "**AI:** \"I don't know your name.\"\n",
    "\n",
    "---\n",
    "\n",
    "### **‚úÖ With Memory**\n",
    "**User:** \"My name is Alice\"  \n",
    "**AI:** \"Nice to meet you, Alice!\"  \n",
    "**User:** \"What's my name?\"  \n",
    "**AI:** \"Your name is Alice.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2debf0c",
   "metadata": {},
   "source": [
    "## üìã LangChain Patterns & Best Practices Cheat Sheet\n",
    "\n",
    "### **Patterns**\n",
    "\n",
    "**üìù Template Chaining** ‚Äì Combine multiple prompts for complex workflows  \n",
    "**Flow:** **`PromptTemplate ‚Üí LLMChain ‚Üí Output`**\n",
    "\n",
    "**üí¨ Conversational AI** ‚Äì Build chatbots with memory and context  \n",
    "**Flow:** **`Memory + ConversationChain`**\n",
    "\n",
    "**üîç Question Answering** ‚Äì Answer questions from documents  \n",
    "**Flow:** **`Documents ‚Üí RetrievalQA`**\n",
    "\n",
    "**ü§ñ Autonomous Agents** ‚Äì AI that can use tools and make decisions  \n",
    "**Flow:** **`Tools + Agent + AgentExecutor`**\n",
    "\n",
    "---\n",
    "\n",
    "### **Best Practices**\n",
    "\n",
    "**üíª Development**  \n",
    "- üîë Use environment variables for API keys  \n",
    "- üõ†Ô∏è Start simple, then gradually add complexity  \n",
    "- ‚úÖ Test prompts thoroughly before production  \n",
    "- üêõ Use `verbose=True` for debugging chains  \n",
    "\n",
    "**üèóÔ∏è Architecture**  \n",
    "- üß© Separate prompts from business logic  \n",
    "- üß† Use appropriate memory types  \n",
    "- ‚ö†Ô∏è Handle errors gracefully  \n",
    "- üí∞ Monitor token usage and costs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning_venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
